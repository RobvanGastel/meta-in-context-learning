{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Outline of GPICL\n",
    "Dataset $D = \\{x_i, y_i\\}$, linear projection $A \\in \\mathcal{R}^{N_x \\times N_x}$ with $A_{ij} \\sim N(0, 1/N_x)$ and final output permutation $\\rho$ , $D = \\{Ax_i, \\rho(y_i)\\}$.\n",
    "\n",
    "this is done to reduce the amount of unique tasks necessary to train our meta-learned model. The loss used is cross-entropy loss, between the label y_j and prediction on the entire series except for the last label. Essentially the same the other notebook leaving out only the last label and adding the set of samples as context.\n",
    "\n",
    "The model a ViT with learned positional embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
